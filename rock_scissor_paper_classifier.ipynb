{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handled-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료\n",
      "994  images to be resized.\n",
      "994  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "1605  images to be resized.\n",
      "1605  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "1265  images to be resized.\n",
      "1265  images resized.\n",
      "보 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 가위 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 바위 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료\")\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 가위 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 바위 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thrown-location",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3864 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 627 입니다.\n",
      "최소값: 0.0  최대값: 1.0\n",
      "x_train shape: (3864, 28, 28, 3)\n",
      "y_train shape: (3864,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image\"\n",
    "(x_train, y_train)=load_data(image_dir_path, 3864)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 627)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#학습 데이터와 테스트 데이터 나누기\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=1004)\n",
    "\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pleased-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 20)        560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 40)        7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 40)          14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 23,651\n",
      "Trainable params: 23,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Before Reshape - x_train_norm shape: (3864, 28, 28, 3)\n",
      "Before Reshape - x_test_norm shape: (627, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (3864, 28, 28, 3)\n",
      "After Reshape - x_test_reshaped shape: (627, 28, 28, 3)\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 1s 3ms/step - loss: 4.5412 - accuracy: 0.4413\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.7598 - accuracy: 0.6520\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7132\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7708\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8254\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8283\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8645\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8857\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8927\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9098\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9203\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9349\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9532\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9526\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9567\n",
      "20/20 - 0s - loss: 3.4177 - accuracy: 0.6667\n",
      "test_loss: 3.4176735877990723 \n",
      "test_accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "n_channel_1=20\n",
    "n_channel_2=40\n",
    "n_channel_3=40\n",
    "n_dense=32\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu')) \n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "''''''''''''''''''''''''''''''\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test.reshape( -1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "#epochs=10 은 총 데이터를 10번 반복 사용해서 학습하라는 내용\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
