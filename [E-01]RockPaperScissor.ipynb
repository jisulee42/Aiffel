{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "simplified-murder",
   "metadata": {},
   "source": [
    "# [EX01]가위바위보 분류기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-budget",
   "metadata": {},
   "source": [
    "## 이미지 사이즈 조정(28x28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "differential-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료\n",
      "2421  images to be resized.\n",
      "2421  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "3037  images to be resized.\n",
      "3037  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "2692  images to be resized.\n",
      "2692  images resized.\n",
      "보 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 가위 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 바위 이미지 resize 완료!\n",
      "209  images to be resized.\n",
      "209  images resized.\n",
      "테스트 보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료\")\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 가위 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 바위 이미지 resize 완료!\")\n",
    "\n",
    "#input data resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"테스트 보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-works",
   "metadata": {},
   "source": [
    "## 각 이미지 및 이미지에 해당하는 라벨 리스트 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "honest-acoustic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 8150 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 627 입니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_image\"\n",
    "(x_train, y_train)=load_data(image_dir_path, 8150)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test_image\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 627)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-spring",
   "metadata": {},
   "source": [
    "## x_train, x_test 이미지의 RGB 각 채널 정규화(/255.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "binding-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n",
      "x_train shape: (8150, 28, 28, 3)\n",
      "y_train shape: (8150,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#학습 데이터와 테스트 데이터 나누기\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=1004)\n",
    "\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-assembly",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "welcome-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 26, 26, 20)        560       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 13, 13, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 11, 11, 40)        7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 5, 5, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 3, 3, 40)          14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 1, 1, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 23,651\n",
      "Trainable params: 23,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "n_channel_1=20 # 이미지 특징의 수\n",
    "n_channel_2=40\n",
    "n_channel_3=40\n",
    "n_dense=32 # 분류기에 사용되는 뉴런의 숫자\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu')) \n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-subscription",
   "metadata": {},
   "source": [
    "## 이미지 데이터 reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "thermal-exhibition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 해당 프로젝트에 필요 없어 주석 처리\\nprint(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\\nprint(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\\n\\nx_train_reshaped=x_train.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\\nx_test_reshaped=x_test.reshape( -1, 28, 28, 3)\\n\\nprint(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\\nprint(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 해당 프로젝트에 필요 없어 주석 처리\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test.reshape( -1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-conflict",
   "metadata": {},
   "source": [
    "## 학습 및 정확성 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "coral-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 2.1813 - accuracy: 0.4212\n",
      "Epoch 2/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.7383 - accuracy: 0.6712\n",
      "Epoch 3/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.5469 - accuracy: 0.7730\n",
      "Epoch 4/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.3736 - accuracy: 0.8570\n",
      "Epoch 5/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.8796\n",
      "Epoch 6/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.2482 - accuracy: 0.9043\n",
      "Epoch 7/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9420\n",
      "Epoch 9/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9491\n",
      "Epoch 10/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9450\n",
      "Epoch 11/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1279 - accuracy: 0.9502\n",
      "Epoch 12/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9393\n",
      "Epoch 13/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9693\n",
      "Epoch 14/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9640\n",
      "Epoch 15/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0753 - accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.9823\n",
      "Epoch 18/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.1562 - accuracy: 0.9506\n",
      "Epoch 19/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9728\n",
      "Epoch 20/20\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9748\n",
      "20/20 - 0s - loss: 3.8668 - accuracy: 0.7273\n",
      "test_loss: 3.866771697998047 \n",
      "test_accuracy: 0.7272727489471436\n"
     ]
    }
   ],
   "source": [
    "#epochs=10 은 총 데이터를 10번 반복 사용해서 학습하라는 내용\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-folder",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-string",
   "metadata": {},
   "source": [
    "> **이번 프로젝트에서 어려웠던 점?**   \n",
    "> train data 수집이 어려웠고, 정확성을 올리는게 어려웠다.   \n",
    "> 처음엔 train data 이미지 수량도 부족하였고, train data 안에 잘못된 이미지 들도 많아 학습이 정상적으로 진행되지 못한 것 같다.(~~그냥 배경만 있는 이미지라던가~~)             \n",
    "> 그러다 보니 정확성이 현저히 낮았다.\n",
    "\n",
    "> **프로젝트를 진행하면서 알아낸점 혹은 아직 모호한점.**   \n",
    "> train data 전처리 및 수량의 중요성을 깨달았다.    \n",
    "> 아직 해당 모델의 구조가 어떤식으로 구동되고, 해당하는 파라미터가 그 구조에서 정확히 어떤 영향을 끼치는지 모호한 것들이 있다.   \n",
    "> 그래서 하나하나 다 수정해보면서 테스트를 진행하였다.\n",
    "\n",
    "> **루브릭 평가 지표를 맞추기 위해 시도한 것들.**      \n",
    "> 1. 하이퍼 파라미터 수정    \n",
    "> : 이미지 특징의 수(n_channel_1,n_channel_2,n_channel_3) 32 ~ 512 까지 순차적으로 늘리거나 줄이면서 테스트를 진행해봤다.       \n",
    "> : 분류기에 사용되는 뉴런의 수(n_dense) 16 ~ 128 까지 늘려보았다.       \n",
    "> : 학습 반복 횟수(n_train_epoch)값을 변경하였다. 내 데이터에서는 20정도 일 때 학습 정확성이 최고값(accuracy: 0.9883)이 나와서 20으로 지정했다.       \n",
    "> 2. 모델의 층수를 추가했다.    \n",
    "> 3. train data  와 test data를 추가 했다.   \n",
    "> : 위의 방법들을 했을 때 정확성이 30프로 정도에서 40프로 대로 올라갔다. 그래서 마지막으로 train data(3000장->8100장), test data(300장->600장)로 수량을 늘리자마자 정확성이 70프로대로 올라갔다.\n",
    ">\n",
    "> 초반 train data를 늘리지 않고 이미지의 특징의 수나 분류기에 사용되는 뉴런의 수, 학습 반복 횟수만 올렸을 때는 오버피팅이 되어 오히려 값이 떨어지기도 하였다.\n",
    "\n",
    "> **자기 다짐**   \n",
    "> : 아직 해당 모델이 정확히 어떻게 구동되는지 잘 알지 못하여서 해당 모델 공부를 더 할것이다.   \n",
    "> : 또한 다른 프로젝트를 진행 시 train data와 test data의 품질과 수량을 올리는데 충분한 시간을 투자해야 될 것 같다.     \n",
    "> : 정확성을 올리기 위해 너무 체계적이지 못하게 테스트를 진행했던 것 같다.(~~노가다로 하이퍼 파라미터 하나하나 바꾸면서~~) 다음 부터는 좀 더 체계적으로 계획을 짜고 테스트를 진행해야 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
